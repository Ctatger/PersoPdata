{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "from random import randint\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, CircleMarker\n",
    "from data_parsing import parse_csv, create_window_dataframe\n",
    "from IPython.display import display\n",
    "from data_parsing import format_time\n",
    "\n",
    "\n",
    "def evaluate_mk(df, mk):\n",
    "    acc_total = 0\n",
    "    for r_id in range(len(df)):\n",
    "\n",
    "        row = df.iloc[[r_id]]\n",
    "        start = row['Start_cluster'].values\n",
    "        pred = mk.predict(str(start[0]))\n",
    "        answ = str(row['End_cluster'].values[0])\n",
    "\n",
    "        if pred == answ:\n",
    "            acc_total += 1\n",
    "    return (acc_total/len(df))*100\n",
    "\n",
    "\n",
    "class generic_markov:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"MK_chain class constructor, computes transition matrix and gamma from given dataframe\n",
    "\n",
    "        Arguments:\n",
    "            df {pandas.dataframe} -- dataframe, containing clusters ID for start and arrival\n",
    "        \"\"\"\n",
    "        # Stored df as class data for ease of use\n",
    "        self.data_frame = df\n",
    "\n",
    "        # List used to store occurences of trip scenario. Used for proba computation\n",
    "        self.sum_mat = []\n",
    "        # Used to check if proba in matrix add up to 1, margin for float approx\n",
    "        self.TOLERANCE_VALUE = 0.0001\n",
    "\n",
    "        # Trip clusters informations\n",
    "        self.Start_clusters = self.data_frame['Start_cluster'].unique()\n",
    "        self.Start_clusters.sort()\n",
    "        self.End_clusters = self.data_frame['End_cluster'].unique()\n",
    "        self.End_clusters.sort()\n",
    "\n",
    "        # Computes and stores Transition matrix and gamma vector\n",
    "        self.create_transition_matrix()\n",
    "\n",
    "    def create_sum_matrix(self):\n",
    "        \"\"\"Parses dataset to store occurences of each start-end cluster combination\n",
    "           Format : [Start, End, nb_occurence]\n",
    "        \"\"\"\n",
    "        for Start in self.Start_clusters:\n",
    "            Total = 0\n",
    "            Starting_points = self.data_frame.loc[self.data_frame['Start_cluster'] == Start]\n",
    "\n",
    "            for End in self.End_clusters:\n",
    "                Ending_points = Starting_points.loc[Starting_points['End_cluster'] == End]\n",
    "                Total = len(Ending_points)\n",
    "\n",
    "                self.sum_mat.append([Start, End, Total])\n",
    "\n",
    "    def create_proba_vector(self, Start):\n",
    "        \"\"\"Creates an array containing probability for each existing end cluster, given a start cluster\n",
    "\n",
    "        Arguments:\n",
    "            Start {int} -- Start cluster for which to compute proba vector\n",
    "\n",
    "        Returns:\n",
    "            np.array -- Probability vector\n",
    "        \"\"\"\n",
    "        size = max(self.End_clusters[-1], self.Start_clusters[-1])\n",
    "\n",
    "        # Avoid crashing in case first trip is from cluster 0 to cluster 0\n",
    "        if size == 0:\n",
    "            size = 1\n",
    "\n",
    "        proba_vector = np.zeros(size+1)\n",
    "        starting_points = self.data_frame.loc[self.data_frame['Start_cluster'] == Start]\n",
    "        sample = len(starting_points)\n",
    "\n",
    "        # Browse through sum_matrix (format [start_cluster, end_cluster, nb_occurence])\n",
    "        for freq in self.sum_mat:\n",
    "            if freq[0] == Start:\n",
    "                # If start_cluster is equal to Start, computes probability\n",
    "                proba_vector[freq[1]] = (freq[2]/sample)*100\n",
    "        return proba_vector\n",
    "\n",
    "    def create_gamma(self):\n",
    "        \"\"\"Computes gamma vector, can be used for first prediction at the start\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Probability in gamma have to add up to 1 (with a tolerated margin)\n",
    "\n",
    "        Returns:\n",
    "            list -- gamma vector, chances of each start cluster to be selected as starting point of trip\n",
    "        \"\"\"\n",
    "        size = max(self.End_clusters[-1], self.Start_clusters[-1])\n",
    "        # Avoid crashing in case first trip is from cluster 0 to cluster 0\n",
    "        if size == 0:\n",
    "            size = 1\n",
    "        sample = len(self.data_frame)\n",
    "\n",
    "        gamma = np.zeros(size+1)\n",
    "\n",
    "        for start in self.Start_clusters:\n",
    "            df_s = self.data_frame.loc[self.data_frame['Start_cluster'] == start]\n",
    "            gamma[start] = ((len(df_s)/sample)*100)\n",
    "        if sum(gamma) > 100.5:\n",
    "            raise ValueError(\"Gamma matrix coefficients not adding up to 1\")\n",
    "        return gamma\n",
    "\n",
    "    def create_transition_matrix(self):\n",
    "        \"\"\"Computes Markov chain's transition matrix, of dimension (n*n) with n the nb of clusters.\n",
    "           Each line is computed using the \"create_proba_vector\" method\n",
    "\n",
    "        Returns:\n",
    "            np.array -- Transition matrix of MK_chain instance\n",
    "        \"\"\"\n",
    "        self.create_sum_matrix()\n",
    "\n",
    "        size = max(self.End_clusters[-1], self.Start_clusters[-1])\n",
    "        # Avoid crashing in case first trip is from cluster 0 to cluster 0\n",
    "        if size == 0:\n",
    "            size = 1\n",
    "        t_mat = np.array(self.create_proba_vector(0))\n",
    "\n",
    "        for i in range(1, size+1):\n",
    "            vect = self.create_proba_vector(i)\n",
    "            t_mat = np.vstack((t_mat, vect))\n",
    "\n",
    "        self.gamma = self.create_gamma()\n",
    "        self.transitionMatrix = t_mat\n",
    "\n",
    "        self.states = [str(x) for x in range(len(self.transitionMatrix))]\n",
    "\n",
    "        return self.gamma, t_mat\n",
    "\n",
    "    def fit(self, new):\n",
    "        \"\"\"Updates transition matrix and gamma vector when new trip is given. Adds the trip to the existing database\n",
    "\n",
    "        Arguments:\n",
    "            new {pandas.dataframe} --Single entry dataframe representing one trip\n",
    "        \"\"\"\n",
    "        start = new['Start_cluster'].values\n",
    "        end = new['End_cluster'].values\n",
    "\n",
    "        frames = [self.data_frame, new]\n",
    "        self.data_frame = pd.concat(frames)\n",
    "\n",
    "        # If new line contains cluster id not existing previously, computing gamma and T_mat all over again is needed\n",
    "        if (start > self.Start_clusters[-1] or end > self.End_clusters[-1]):\n",
    "            self.Start_clusters = self.data_frame['Start_cluster'].unique()\n",
    "            self.Start_clusters.sort()\n",
    "            self.End_clusters = self.data_frame['End_cluster'].unique()\n",
    "            self.End_clusters.sort()\n",
    "\n",
    "            self.create_transition_matrix()\n",
    "\n",
    "        else:\n",
    "            self.Start_clusters = self.data_frame['Start_cluster'].unique()\n",
    "            self.Start_clusters.sort()\n",
    "            self.End_clusters = self.data_frame['End_cluster'].unique()\n",
    "            self.End_clusters.sort()\n",
    "\n",
    "            for start_point in start:\n",
    "                for end_point in end:\n",
    "                    for freq in self.sum_mat:\n",
    "\n",
    "                        if (freq[0] == start_point and freq[1] == end_point):\n",
    "                            new_id = self.sum_mat.index(freq)\n",
    "                            self.sum_mat[new_id][2] += 1\n",
    "\n",
    "            for i in start:\n",
    "                vect = self.create_proba_vector(i)\n",
    "                self.transitionMatrix[i] = vect\n",
    "                self.gamma = self.create_gamma()\n",
    "\n",
    "    def predict(self, curr_st):\n",
    "        \"\"\"Gives id of predicted end cluster, given start of trip\n",
    "\n",
    "        Arguments:\n",
    "            curr_st {str} -- Id of current trip starting cluster\n",
    "\n",
    "        Returns:\n",
    "            str -- Predicted end cluster for trip\n",
    "        \"\"\"\n",
    "        if curr_st in self.states:\n",
    "            st_id = self.states.index(curr_st)\n",
    "            most_likely = max(self.transitionMatrix[st_id])\n",
    "            pred_id = np.where(self.transitionMatrix[st_id] == most_likely)[0][0]\n",
    "            return self.states[pred_id]\n",
    "        else:\n",
    "            # If given cluster Id not existing in states, outputs -1\n",
    "            return('-1')\n",
    "\n",
    "    def gamma_predict(self):\n",
    "\n",
    "        pred_vect = np.matmul(self.gamma, self.transitionMatrix)\n",
    "        pred = np.where(pred_vect == max(pred_vect))[0][0]\n",
    "\n",
    "        return str(pred)\n",
    "\n",
    "\n",
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sns.set_theme()\n",
    "    palette = plt.get_cmap('Set1')\n",
    "    figure(figsize=(16, 14), dpi=80)\n",
    "\n",
    "    RANGE = 100\n",
    "    # df_wind = pd.DataFrame(columns=['Pos', 'Start_cluster', 'End_cluster', 'Wd_state', 'Day', 'Time', 'Time_delta'])\n",
    "    window_state = []\n",
    "    days = [randint(0, 6) for x in range(RANGE)]\n",
    "    # possible_adresses = [\"golf\", \"RSWL\",\"maison st cyp\", \"maison cote pavee\",\"maison saint agne\"]\n",
    "    possible_adresses = [[43.575319, 1.364180], [43.579300, 1.378159], [43.597517, 1.433078], [43.594339, 1.465000],\n",
    "                         [43.583054, 1.450124]]\n",
    "    adresses_polygon = [[43.575414, 1.364311, 43.575223, 1.364048],\n",
    "                        [43.579395, 1.378290, 43.579204, 1.378027],\n",
    "                        [43.597612, 1.433209, 43.597421, 1.432946],\n",
    "                        [43.594434, 1.465131, 43.594243, 1.464868],\n",
    "                        [43.583149, 1.450255, 43.582958, 1.449992]]\n",
    "\n",
    "    for k in range(10):\n",
    "        rand = np.random.choice(list(range(5)), RANGE, p=[0.05, 0.5, 0.1, 0.1, 0.25])\n",
    "        adresses = [[random.uniform(adresses_polygon[i][2], adresses_polygon[i][0]),\n",
    "                     random.uniform(adresses_polygon[i][3], adresses_polygon[i][1])]\n",
    "                    for i in rand]\n",
    "\n",
    "        Starting_hours = np.linspace(9, 10.15)\n",
    "        Stopping_hours = np.linspace(17, 18.15)\n",
    "\n",
    "        possible_times = np.concatenate([Starting_hours, Stopping_hours])\n",
    "        random_times = np.random.choice(possible_times, RANGE)\n",
    "        Time = []\n",
    "\n",
    "        FMT = '%H:%M'\n",
    "        for index in range(RANGE):\n",
    "            Time.append(format_time(random_times[index]))\n",
    "            if (rand[index] == 0 or rand[index] == 1):\n",
    "                window_state.append(np.random.choice([0, 1], 1, p=[0.8, 0.2]))\n",
    "            else:\n",
    "                window_state.append(np.random.choice([0, 1], 1, p=[0.01, 0.99]))\n",
    "\n",
    "        with open('/home/celadodc-rswl.com/corentin.tatger/PersoPdata/app_data/dummy_data_{}.csv'.format(k),\n",
    "                  mode='w') as csv_file:\n",
    "            fieldnames = ['Pos_lat', 'Pos_lon', 'Wd_state', 'Time', 'Day']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()\n",
    "            for i in range(RANGE):\n",
    "                writer.writerow({'Pos_lat': adresses[i][0], 'Pos_lon': adresses[i][1], 'Wd_state': window_state[i][0],\n",
    "                                 'Time': Time[i], 'Day': days[i]})\n",
    "\n",
    "    df_csv = parse_csv(\n",
    "        \"/home/celadodc-rswl.com/corentin.tatger/PersoPdata/app_data/\")\n",
    "    df_window = create_window_dataframe(df_csv)\n",
    "    # display(df_window)\n",
    "    rec_colors = ['blue', 'red', 'orange', 'yellow', 'brown', 'green']\n",
    "    map_layer = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "    m = Map(layers=(map_layer, ), center=((48.852, 2.246)), zoom=5, scroll_wheel_zoom=True)\n",
    "\n",
    "    for index, row in df_window.iterrows():\n",
    "        if row['Coord_cluster'] >= 0:\n",
    "            m.add_layer(CircleMarker(location=row['Coordinates'], radius=3,\n",
    "                                     color=rec_colors[row['Coord_cluster'] % len(rec_colors)],\n",
    "                                     fill_color='#FFFFFF', weight=2))\n",
    "    display(m)\n",
    "    m.save('my_map.html', title='My Map')\n",
    "\n",
    "    epoch_acc = []\n",
    "    for i in range(10):\n",
    "        df_window = df_window.sample(frac=1)\n",
    "        df_train = df_window.sample(frac=0.7)\n",
    "        df_test = df_window.drop(df_train.index)\n",
    "\n",
    "        Mk_chain = generic_markov(df_train.head())\n",
    "        current_acc = [evaluate_mk(df_test, Mk_chain)]\n",
    "\n",
    "        for row_id in range(5, len(df_train)):\n",
    "            Mk_chain.fit(df_train.iloc[[row_id]])\n",
    "            current_acc.append(evaluate_mk(df_test, Mk_chain))\n",
    "\n",
    "        epoch_acc.append(current_acc)\n",
    "        print(\"Epoch {} done.\".format(i))\n",
    "\n",
    "    # plt.plot(list(range(30)), epoch_acc)\n",
    "    # plt.plot(list(range(30)), [np.mean(epoch_acc) for i in range(30)])\n",
    "    # plt.title(\"Mean accuracy of model is {}%\".format(np.mean(epoch_acc)))\n",
    "    # ax = plt.gca()\n",
    "    # ax.set_ylim([60, 100])\n",
    "    # plt.show()\n",
    "\n",
    "    # Create figure\n",
    "    gofig = go.Figure()\n",
    "    # Add traces, one for each slider step\n",
    "    for step in range(10):\n",
    "        gofig.add_trace(\n",
    "            go.Scatter(\n",
    "                visible=False,\n",
    "                line=dict(color=\"#00CED1\", width=6),\n",
    "                name=\"v = \" + str(step),\n",
    "                x=np.arange(0, len(df_train), 1),\n",
    "                y=epoch_acc[step]))\n",
    "        gofig.update_yaxes(range=[0, 100])\n",
    "\n",
    "    # Make 10th trace visible\n",
    "    gofig.data[0].visible = True\n",
    "\n",
    "    # Create and add slider\n",
    "    steps = []\n",
    "    for i in range(len(gofig.data)):\n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            args=[{\"visible\": [False] * len(gofig.data)},\n",
    "                  {\"title\": \"Evolution of Markov Accuracy's\"}],  # layout attribute\n",
    "        )\n",
    "        step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=10,\n",
    "        currentvalue={\"prefix\": \"Frequency: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps\n",
    "    )]\n",
    "\n",
    "    gofig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "    gofig.show()\n",
    "\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
